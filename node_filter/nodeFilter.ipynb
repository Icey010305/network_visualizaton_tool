{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_file = 'Filtered_HepTh_edges.txt'\n",
    "details_file = 'updated_paper_details.txt'\n",
    "pagerank_file = 'HepTh_pagerank_results.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter nodes based on largest Scc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 25031\n",
      "Number of edges: 324459\n"
     ]
    }
   ],
   "source": [
    "# 1. Read original data\n",
    "\n",
    "# Create a direct graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "with open(network_file, \"r\") as file:\n",
    "    for line_number, line in enumerate(file, start=1):\n",
    "        # Remove the Spaces at both ends of the line and split it into a list of nodes\n",
    "        nodes = line.strip().split()\n",
    "        if len(nodes) != 2:\n",
    "            print(f\"Error: Line {line_number} does not contain exactly two nodes.\")\n",
    "            break\n",
    "        else:\n",
    "            node1, node2 = nodes\n",
    "            G.add_edge(node1, node2)\n",
    "print(\"Number of nodes:\", G.number_of_nodes())\n",
    "print(\"Number of edges:\", G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest SCC with 13056 nodes and 203852 edges saved to 'edges.txt'.\n"
     ]
    }
   ],
   "source": [
    "# 2. Identify the maximum strongly connected component (SCC)\n",
    "largest_scc = max(nx.strongly_connected_components(G), key=len)\n",
    "\n",
    "# 3. Extract the subgraph in the maximum SCC\n",
    "largest_scc_subgraph = G.subgraph(largest_scc).copy()\n",
    "\n",
    "# 4. Save the maximum SCC to a new file\n",
    "with open('edges.txt', 'w') as file:\n",
    "    for edge in largest_scc_subgraph.edges():\n",
    "        file.write(f\"{edge[0]} {edge[1]}\\n\")\n",
    "\n",
    "print(f\"Largest SCC with {len(largest_scc_subgraph.nodes())} nodes and {len(largest_scc_subgraph.edges())} edges saved to 'edges.txt'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the PageRank result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_network(file_path):\n",
    "    G = nx.DiGraph()\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            source, target = line.strip().split()\n",
    "            G.add_edge(source, target)\n",
    "    return G\n",
    "\n",
    "def read_dates(file_path):\n",
    "    dates = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for idx, line in enumerate(file):\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) < 3:\n",
    "                continue  \n",
    "            \n",
    "            paper_id = parts[0].strip()\n",
    "            title = parts[1].strip()\n",
    "            date = parts[2].strip()\n",
    "            \n",
    "            dates[str(idx + 1)] = (paper_id, title, date)\n",
    "    return dates\n",
    "\n",
    "def calculate_weights(G, dates, current_year=2024, lambda_decay=0.1):\n",
    "    citation_counts = {node: 0 for node in G.nodes()}\n",
    "    for _, target in G.edges():\n",
    "        citation_counts[target] += 1\n",
    "    \n",
    "    time_decay = {node: np.exp(-lambda_decay * (current_year - int(dates[node][1].split('-')[0]))) for node in G.nodes() if node in dates}\n",
    "    \n",
    "    weights = {node: citation_counts[node] * time_decay.get(node, 0) for node in G.nodes()}\n",
    "    return weights\n",
    "\n",
    "def weighted_pagerank(G, weights, alpha=0.85, max_iter=100, tol=1.0e-6):\n",
    "    N = len(G)\n",
    "    pagerank = {node: 1.0 / N for node in G}\n",
    "    for _ in range(max_iter):\n",
    "        new_pagerank = {}\n",
    "        for node in G:\n",
    "            rank_sum = 0\n",
    "            for pred in G.predecessors(node):\n",
    "                weight_sum = sum(weights[succ] for succ in G.successors(pred))\n",
    "                if weight_sum != 0:\n",
    "                    rank_sum += pagerank[pred] * weights[pred] / weight_sum\n",
    "            new_pagerank[node] = (1 - alpha) / N + alpha * rank_sum\n",
    "        if all(abs(new_pagerank[node] - pagerank[node]) < tol for node in pagerank):\n",
    "            return new_pagerank\n",
    "        pagerank = new_pagerank\n",
    "    return pagerank\n",
    "\n",
    "def get_important_nodes(pagerank):\n",
    "    sorted_nodes = sorted(pagerank, key=pagerank.get, reverse=True)\n",
    "    return sorted_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "G = read_network('edges.txt')\n",
    "dates = read_dates(details_file)\n",
    "\n",
    "# Calculate\n",
    "weights = calculate_weights(G, dates)\n",
    "\n",
    "# Calculate PageRank\n",
    "pagerank = weighted_pagerank(G, weights)\n",
    "\n",
    "# Gets nodes in order of importance\n",
    "important_nodes = get_important_nodes(pagerank)\n",
    "\n",
    "# Save results\n",
    "with open(pagerank_file, 'w') as file:\n",
    "    json.dump({'pagerank': pagerank, 'important_nodes': important_nodes}, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "network_vis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
